name: ETL Pipeline CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - test
          - prod

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black mypy
        pip install -r requirements.txt
        
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Check formatting with black
      run: |
        black --check .
        
    - name: Type check with mypy
      run: |
        mypy --ignore-missing-imports etl/

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        pip install -r requirements.txt
        
    - name: Run tests
      run: |
        pytest tests/ --cov=etl --cov-report=xml
        
    - name: Upload coverage report
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false

  build:
    name: Build Artifacts
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create Lambda layers
      run: |
        mkdir -p build/lambda/layers
        python infrastructure/lambda/create_config_layer.py
        
    - name: Generate Lambda functions
      run: |
        python infrastructure/lambda/generate_lambda_functions.py
        
    - name: Package Lambda functions
      run: |
        mkdir -p build/lambda
        for file in infrastructure/lambda/*.py; do
          if [[ $(basename $file) != "create_config_layer.py" && $(basename $file) != "generate_lambda_functions.py" && $(basename $file) != "lambda_template.py" ]]; then
            zip -j build/lambda/$(basename ${file%.py}).zip $file
          fi
        done
        
    - name: Upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: etl-artifacts
        path: |
          build/
          infrastructure/step_functions/
          infrastructure/cloudformation/

  deploy-dev:
    name: Deploy to Dev
    runs-on: ubuntu-latest
    needs: build
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'dev')
    environment: dev
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: etl-artifacts
        path: .
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
        
    - name: Create S3 bucket if not exists
      run: |
        aws s3api head-bucket --bucket ${{ secrets.S3_BUCKET_NAME }} 2>/dev/null || aws s3 mb s3://${{ secrets.S3_BUCKET_NAME }} --region ${{ secrets.AWS_REGION }}
        
    - name: Upload artifacts to S3
      run: |
        aws s3 cp build/lambda/layers/config_layer.zip s3://${{ secrets.S3_BUCKET_NAME }}/lambda/layers/config_layer.zip
        aws s3 cp infrastructure/step_functions/etl_state_machine.json s3://${{ secrets.S3_BUCKET_NAME }}/step_functions/etl_state_machine.json
        for file in build/lambda/*.zip; do
          aws s3 cp $file s3://${{ secrets.S3_BUCKET_NAME }}/lambda/$(basename $file)
        done
        
    - name: Deploy CloudFormation stack
      run: |
        aws cloudformation deploy \
          --template-file infrastructure/cloudformation/etl_pipeline.yaml \
          --stack-name ${{ secrets.STACK_NAME }}-dev \
          --capabilities CAPABILITY_IAM \
          --parameter-overrides \
            S3BucketName=${{ secrets.S3_BUCKET_NAME }} \
            GlueJobPrefix=${{ secrets.GLUE_JOB_PREFIX }}-dev \
            AwsRegion=${{ secrets.AWS_REGION }} \
            ConfigLayerS3Key=lambda/layers/config_layer.zip

  deploy-test:
    name: Deploy to Test
    runs-on: ubuntu-latest
    needs: deploy-dev
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'test'
    environment: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: etl-artifacts
        path: .
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
        
    - name: Create S3 bucket if not exists
      run: |
        aws s3api head-bucket --bucket ${{ secrets.S3_BUCKET_NAME }} 2>/dev/null || aws s3 mb s3://${{ secrets.S3_BUCKET_NAME }} --region ${{ secrets.AWS_REGION }}
        
    - name: Upload artifacts to S3
      run: |
        aws s3 cp build/lambda/layers/config_layer.zip s3://${{ secrets.S3_BUCKET_NAME }}/lambda/layers/config_layer.zip
        aws s3 cp infrastructure/step_functions/etl_state_machine.json s3://${{ secrets.S3_BUCKET_NAME }}/step_functions/etl_state_machine.json
        for file in build/lambda/*.zip; do
          aws s3 cp $file s3://${{ secrets.S3_BUCKET_NAME }}/lambda/$(basename $file)
        done
        
    - name: Deploy CloudFormation stack
      run: |
        aws cloudformation deploy \
          --template-file infrastructure/cloudformation/etl_pipeline.yaml \
          --stack-name ${{ secrets.STACK_NAME }}-test \
          --capabilities CAPABILITY_IAM \
          --parameter-overrides \
            S3BucketName=${{ secrets.S3_BUCKET_NAME }} \
            GlueJobPrefix=${{ secrets.GLUE_JOB_PREFIX }}-test \
            AwsRegion=${{ secrets.AWS_REGION }} \
            ConfigLayerS3Key=lambda/layers/config_layer.zip

  deploy-prod:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-dev, deploy-test]
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'prod'
    environment: prod
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: etl-artifacts
        path: .
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
        
    - name: Create S3 bucket if not exists
      run: |
        aws s3api head-bucket --bucket ${{ secrets.S3_BUCKET_NAME }} 2>/dev/null || aws s3 mb s3://${{ secrets.S3_BUCKET_NAME }} --region ${{ secrets.AWS_REGION }}
        
    - name: Upload artifacts to S3
      run: |
        aws s3 cp build/lambda/layers/config_layer.zip s3://${{ secrets.S3_BUCKET_NAME }}/lambda/layers/config_layer.zip
        aws s3 cp infrastructure/step_functions/etl_state_machine.json s3://${{ secrets.S3_BUCKET_NAME }}/step_functions/etl_state_machine.json
        for file in build/lambda/*.zip; do
          aws s3 cp $file s3://${{ secrets.S3_BUCKET_NAME }}/lambda/$(basename $file)
        done
        
    - name: Deploy CloudFormation stack
      run: |
        aws cloudformation deploy \
          --template-file infrastructure/cloudformation/etl_pipeline.yaml \
          --stack-name ${{ secrets.STACK_NAME }} \
          --capabilities CAPABILITY_IAM \
          --parameter-overrides \
            S3BucketName=${{ secrets.S3_BUCKET_NAME }} \
            GlueJobPrefix=${{ secrets.GLUE_JOB_PREFIX }} \
            AwsRegion=${{ secrets.AWS_REGION }} \
            ConfigLayerS3Key=lambda/layers/config_layer.zip
